üéØ Midterm Project ‚Äî Predicting Student Dropout and Academic Success
1. üß© Problem Description
Contexto

El abandono universitario es uno de los principales desaf√≠os en educaci√≥n superior. Predecir de manera temprana qu√© estudiantes tienen mayor riesgo de abandonar puede ayudar a las instituciones a tomar medidas preventivas, ofreciendo apoyo acad√©mico o financiero.

Objetivo

Desarrollar un modelo de Machine Learning capaz de predecir si un estudiante terminar√° gradu√°ndose, continuar√° matriculado o abandonar√° los estudios, utilizando datos acad√©micos, demogr√°ficos y socioecon√≥micos.

Dataset

Fuente: UCI Machine Learning Repository ‚Äì Predict Students Dropout and Academic Success

Tama√±o: 4 424 registros

Features: 35 variables (edad, g√©nero, notas, becas, tipo de curso, situaci√≥n econ√≥mica, etc.)

Target: Target (categor√≠as: Dropout, Enrolled, Graduate)

2. üìä Exploratory Data Analysis (EDA)
Objetivos del EDA

Analizar la distribuci√≥n de la variable objetivo (balance de clases).

Identificar correlaciones entre rendimiento acad√©mico y abandono.

Explorar el impacto de variables socioecon√≥micas (por ejemplo, becas, edad, empleo).

Detectar valores faltantes o at√≠picos.

Ejemplos de gr√°ficos √∫tiles

countplot del target (distribuci√≥n Dropout / Enrolled / Graduate)

boxplot de notas finales vs target

heatmap de correlaciones

barplot de tasa de abandono por g√©nero o tipo de curso

3. ‚öôÔ∏è Data Preparation
Posibles pasos

Limpieza de datos:

Manejar NaN o valores extremos.

Convertir variables categ√≥ricas (e.g., ‚Äúgender‚Äù, ‚Äúcourse‚Äù) a num√©ricas con OneHotEncoder o DictVectorizer.

Feature engineering:

Crear variables derivadas como:

Promedio de notas de primer a√±o.

Ratio de asignaturas aprobadas/reprobadas.

Variables binarias de apoyo econ√≥mico.

Normalizaci√≥n / estandarizaci√≥n:

Escalar variables num√©ricas si usas modelos sensibles (p. ej. regresi√≥n log√≠stica, SVM).

4. ü§ñ Model Training and Evaluation
Modelos a probar

Regresi√≥n Log√≠stica Multiclase (baseline)

Random Forest Classifier

XGBoost / LightGBM

(Opcional) Support Vector Machine si los datos est√°n bien escalados

M√©tricas recomendadas

Accuracy (para comparar modelos)

F1-score macro (para evitar sesgos por clases desbalanceadas)

Confusion Matrix

ROC-AUC por clase (si usas binarizaci√≥n)

Validaci√≥n

train_test_split (70/30 o 80/20)

Validaci√≥n cruzada (cross_val_score) o GridSearchCV para tuning de hiperpar√°metros.

5. üß™ Model Selection and Interpretation

Escoge el mejor modelo en base a F1-macro o balanced accuracy.

Interpreta feature importances o SHAP values:

¬øQu√© variables influyen m√°s en el abandono?

¬øFactores financieros o acad√©micos?

Discute las implicaciones educativas:

C√≥mo podr√≠a usarse este modelo en una universidad para detectar riesgo.

6. üì¶ Export and Deployment
Exportar modelo

Usa joblib o pickle para guardar el modelo final (model.pkl).

Guarda tambi√©n el preprocesador (dv.pkl si usas DictVectorizer).

Crear servicio web

Escribe un script predict.py o app.py con Flask o FastAPI:











Para ejecutar el Docker
docker build -t student-model .
docker run -p 8000:8000 student-model
